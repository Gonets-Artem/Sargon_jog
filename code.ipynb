{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b74b8da0",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ca9392-81f0-49a3-9847-41bbc8622d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from random import random, randint, shuffle\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e90b71",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae06e898",
   "metadata": {},
   "source": [
    "### Dataset 1 - StudentPerformanceFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a36c2cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_1(file):\n",
    "    df = pd.read_csv('StudentPerformanceFactors.csv')\n",
    "    df = df.dropna()\n",
    "    df['Parental_Involvement'] = df['Parental_Involvement'].map({'High': 2, 'Medium': 1, 'Low': 0})\n",
    "    df['Access_to_Resources'] = df['Access_to_Resources'].map({'High': 2, 'Medium': 1, 'Low': 0})\n",
    "    df['Extracurricular_Activities'] = df['Extracurricular_Activities'].map({'Yes': 1, 'No': 0})\n",
    "    df['Motivation_Level'] = df['Motivation_Level'].map({'High': 2, 'Medium': 1, 'Low': 0})\n",
    "    df['Internet_Access'] = df['Internet_Access'].map({'Yes': 1, 'No': 0})\n",
    "    df['Family_Income'] = df['Family_Income'].map({'High': 2, 'Medium': 1, 'Low': 0})\n",
    "    df['Teacher_Quality'] = df['Teacher_Quality'].map({'High': 2, 'Medium': 1, 'Low': 0})\n",
    "    df['School_Type'] = df['School_Type'].map({'Public': 1, 'Private': 0})\n",
    "    df['Peer_Influence'] = df['Peer_Influence'].map({'Positive': 2, 'Neutral': 1, 'Negative': 0})\n",
    "    df['Learning_Disabilities'] = df['Learning_Disabilities'].map({'Yes': 1, 'No': 0})\n",
    "    df['Parental_Education_Level'] = df['Parental_Education_Level'].map({'Postgraduate': 2, 'High School': 1, 'College': 0})\n",
    "    df['Distance_from_Home'] = df['Distance_from_Home'].map({'Far': 2, 'Moderate': 1, 'Near': 0})\n",
    "    df['Gender'] = df['Gender'].map({'Female': 1, 'Male': 0})\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.loc[:, df.columns[:-1]], \n",
    "                                                        df.loc[:, df.columns[-1]], \n",
    "                                                        test_size=0.2, random_state=42)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    scaled_X_train = scaler.transform(X_train)\n",
    "    scaled_X_test = scaler.transform(X_test)\n",
    "    return df, scaled_X_train, scaled_X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f23c65-f0e5-4d7f-a7d1-4229fb54749d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hours_Studied</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>Parental_Involvement</th>\n",
       "      <th>Access_to_Resources</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Sleep_Hours</th>\n",
       "      <th>Previous_Scores</th>\n",
       "      <th>Motivation_Level</th>\n",
       "      <th>Internet_Access</th>\n",
       "      <th>Tutoring_Sessions</th>\n",
       "      <th>Family_Income</th>\n",
       "      <th>Teacher_Quality</th>\n",
       "      <th>School_Type</th>\n",
       "      <th>Peer_Influence</th>\n",
       "      <th>Physical_Activity</th>\n",
       "      <th>Learning_Disabilities</th>\n",
       "      <th>Parental_Education_Level</th>\n",
       "      <th>Distance_from_Home</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Exam_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>25</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>23</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6605</th>\n",
       "      <td>10</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>15</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6378 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Hours_Studied  Attendance  Parental_Involvement  Access_to_Resources  \\\n",
       "0                23          84                     0                    2   \n",
       "1                19          64                     0                    1   \n",
       "2                24          98                     1                    1   \n",
       "3                29          89                     0                    1   \n",
       "4                19          92                     1                    1   \n",
       "...             ...         ...                   ...                  ...   \n",
       "6602             25          69                     2                    1   \n",
       "6603             23          76                     2                    1   \n",
       "6604             20          90                     1                    0   \n",
       "6605             10          86                     2                    2   \n",
       "6606             15          67                     1                    0   \n",
       "\n",
       "      Extracurricular_Activities  Sleep_Hours  Previous_Scores  \\\n",
       "0                              0            7               73   \n",
       "1                              0            8               59   \n",
       "2                              1            7               91   \n",
       "3                              1            8               98   \n",
       "4                              1            6               65   \n",
       "...                          ...          ...              ...   \n",
       "6602                           0            7               76   \n",
       "6603                           0            8               81   \n",
       "6604                           1            6               65   \n",
       "6605                           1            6               91   \n",
       "6606                           1            9               94   \n",
       "\n",
       "      Motivation_Level  Internet_Access  Tutoring_Sessions  Family_Income  \\\n",
       "0                    0                1                  0              0   \n",
       "1                    0                1                  2              1   \n",
       "2                    1                1                  2              1   \n",
       "3                    1                1                  1              1   \n",
       "4                    1                1                  3              1   \n",
       "...                ...              ...                ...            ...   \n",
       "6602                 1                1                  1              2   \n",
       "6603                 1                1                  3              0   \n",
       "6604                 0                1                  3              0   \n",
       "6605                 2                1                  2              0   \n",
       "6606                 1                1                  0              1   \n",
       "\n",
       "      Teacher_Quality  School_Type  Peer_Influence  Physical_Activity  \\\n",
       "0                   1            1               2                  3   \n",
       "1                   1            1               0                  4   \n",
       "2                   1            1               1                  4   \n",
       "3                   1            1               0                  4   \n",
       "4                   2            1               1                  4   \n",
       "...               ...          ...             ...                ...   \n",
       "6602                1            1               2                  2   \n",
       "6603                2            1               2                  2   \n",
       "6604                1            1               0                  2   \n",
       "6605                1            0               2                  3   \n",
       "6606                1            1               2                  4   \n",
       "\n",
       "      Learning_Disabilities  Parental_Education_Level  Distance_from_Home  \\\n",
       "0                         0                         1                   0   \n",
       "1                         0                         0                   1   \n",
       "2                         0                         2                   0   \n",
       "3                         0                         1                   1   \n",
       "4                         0                         0                   0   \n",
       "...                     ...                       ...                 ...   \n",
       "6602                      0                         1                   0   \n",
       "6603                      0                         1                   0   \n",
       "6604                      0                         2                   0   \n",
       "6605                      0                         1                   2   \n",
       "6606                      0                         2                   0   \n",
       "\n",
       "      Gender  Exam_Score  \n",
       "0          0          67  \n",
       "1          1          61  \n",
       "2          0          74  \n",
       "3          0          71  \n",
       "4          1          70  \n",
       "...      ...         ...  \n",
       "6602       1          68  \n",
       "6603       1          69  \n",
       "6604       1          68  \n",
       "6605       1          68  \n",
       "6606       0          64  \n",
       "\n",
       "[6378 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1, scaled_X_train_1, scaled_X_test_1, y_train_1, y_test_1 = dataset_1('StudentPerformanceFactors.csv')\n",
    "df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12c1329",
   "metadata": {},
   "source": [
    "### Dataset 2 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "257a179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_2(file):\n",
    "    df = pd.read_csv(file)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.loc[:, df.columns[:-1]], \n",
    "                                                        df.loc[:, df.columns[-1]], \n",
    "                                                        test_size=0.2, random_state=42)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    scaled_X_train = scaler.transform(X_train)\n",
    "    scaled_X_test = scaler.transform(X_test)\n",
    "    return df, scaled_X_train, scaled_X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe4c9355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>18.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  Radio  Newspaper  Sales\n",
       "0    230.1   37.8       69.2   22.1\n",
       "1     44.5   39.3       45.1   10.4\n",
       "2     17.2   45.9       69.3   12.0\n",
       "3    151.5   41.3       58.5   16.5\n",
       "4    180.8   10.8       58.4   17.9\n",
       "..     ...    ...        ...    ...\n",
       "195   38.2    3.7       13.8    7.6\n",
       "196   94.2    4.9        8.1   14.0\n",
       "197  177.0    9.3        6.4   14.8\n",
       "198  283.6   42.0       66.2   25.5\n",
       "199  232.1    8.6        8.7   18.4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2, scaled_X_train_2, scaled_X_test_2, y_train_2, y_test_2 = dataset_2('advertising.csv')\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b3f736",
   "metadata": {},
   "source": [
    "### Dataset 3 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd823381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_3(file):\n",
    "    column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "    df = pd.read_csv(file, header=None, delimiter=r\"\\s+\", names=column_names)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.loc[:, df.columns[:-1]], \n",
    "                                                        df.loc[:, df.columns[-1]], \n",
    "                                                        test_size=0.2, random_state=42)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "    scaled_X_train = scaler.transform(X_train)\n",
    "    scaled_X_test = scaler.transform(X_test)\n",
    "    return df, scaled_X_train, scaled_X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5df04a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273.0   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273.0   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273.0   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273.0   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3, scaled_X_train_3, scaled_X_test_3, y_train_3, y_test_3 = dataset_3('housing.csv')\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36772955",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a329a561-8432-4f40-af9e-dde65e26dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, num_input, num_neurons, number=None):\n",
    "        super(NeuronNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=num_input, out_features=num_neurons)\n",
    "        self.fc2 = nn.Linear(in_features=num_neurons, out_features=1)\n",
    "        self.number = number\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "548dbd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "df_1 = pd.DataFrame(columns=['method', 'L2', 'time'])\n",
    "df_2 = pd.DataFrame(columns=['method', 'L2', 'time'])\n",
    "df_3 = pd.DataFrame(columns=['method', 'L2', 'time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68be9d90",
   "metadata": {},
   "source": [
    "## Basic Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "522cb199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, scheduler, loss, inputs, targets, epochs):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f'epoch num: {epoch}')\n",
    "        for i, row in enumerate(inputs):\n",
    "\n",
    "            data = torch.tensor(row).type(torch.FloatTensor).to(device)\n",
    "            target = torch.tensor(np.array(targets.iloc[i])).type(torch.FloatTensor).to(device).view(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(data)\n",
    "            loss_value = loss(pred, target)\n",
    "\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step(loss_value)\n",
    "\n",
    "\n",
    "def test_model(model, inputs, targets, file=\"test.txt\"):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    running_l2 = 0.  \n",
    "    with open(file, 'w') as f:\n",
    "        pass\n",
    "\n",
    "    for i, row in enumerate(inputs):\n",
    "        data = torch.tensor(row).type(torch.FloatTensor).to(device)\n",
    "        target = torch.tensor(np.array(targets.iloc[i])).type(torch.FloatTensor).to(device).view(1)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred = model(data)\n",
    "        r = '{} Pred: {:.4f} Target: {:.4f}'.format(i, round(pred.item()), target.item())\n",
    "        with open(file, 'a') as f:\n",
    "            f.write(r + '\\n')\n",
    "\n",
    "        eps = abs(target.item() - pred.item())\n",
    "        running_l2 += eps ** 2\n",
    "\n",
    "    l2 = (running_l2 / inputs.shape[0]) ** 0.5\n",
    "    with open(file, 'a') as f:\n",
    "        f.write(f'L2: {round(l2, 2)}')\n",
    "    print('Test\\tL2: {:.2f}'.format(l2), flush=True)\n",
    "\n",
    "    return l2\n",
    "\n",
    "\n",
    "def basic(scaled_X_train, y_train, scaled_X_test, y_test, num_neurons, epochs, file):\n",
    "    loss = nn.MSELoss()\n",
    "    model = NeuronNetwork(num_input=scaled_X_train.shape[1], num_neurons=num_neurons).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10000, min_lr=1e-06)\n",
    "\n",
    "    train_model(model, optimizer, scheduler, loss, scaled_X_train, y_train, epochs=epochs)\n",
    "    return test_model(model, scaled_X_test, y_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5df96575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch num: 1\n",
      "epoch num: 2\n",
      "epoch num: 3\n",
      "epoch num: 4\n",
      "epoch num: 5\n",
      "Test\tL2: 2.12\n",
      "epoch num: 1\n",
      "epoch num: 2\n",
      "epoch num: 3\n",
      "epoch num: 4\n",
      "epoch num: 5\n",
      "Test\tL2: 2.12\n",
      "epoch num: 1\n",
      "epoch num: 2\n",
      "epoch num: 3\n",
      "epoch num: 4\n",
      "epoch num: 5\n",
      "Test\tL2: 2.12\n"
     ]
    }
   ],
   "source": [
    "res_basic_1 = []\n",
    "start = time()\n",
    "for j in range(3):\n",
    "    res_basic_1.append(\n",
    "        basic(scaled_X_train_1, y_train_1, scaled_X_test_1, y_test_1, \n",
    "                  num_neurons=20, \n",
    "                  epochs=5, \n",
    "                  file=f\"final_basic_1_{j}.txt\"\n",
    "        )\n",
    "    )\n",
    "end = time()\n",
    "avg_res = round(sum(res_basic_1) / len(res_basic_1), 2)\n",
    "avg_time = round(end - start)\n",
    "df_1.loc[-1] = ['basic', avg_res, avg_time]\n",
    "df_1.index = df_1.index + 1\n",
    "df_1 = df_1.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d5bc6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch num: 1\n",
      "epoch num: 2\n",
      "epoch num: 3\n",
      "epoch num: 4\n",
      "epoch num: 5\n",
      "Test\tL2: 4.85\n",
      "epoch num: 1\n",
      "epoch num: 2\n",
      "epoch num: 3\n",
      "epoch num: 4\n",
      "epoch num: 5\n",
      "Test\tL2: 4.87\n",
      "epoch num: 1\n",
      "epoch num: 2\n",
      "epoch num: 3\n",
      "epoch num: 4\n",
      "epoch num: 5\n",
      "Test\tL2: 4.81\n"
     ]
    }
   ],
   "source": [
    "res_basic_2 = []\n",
    "start = time()\n",
    "for j in range(3):\n",
    "    res_basic_2.append(\n",
    "        basic(scaled_X_train_2, y_train_2, scaled_X_test_2, y_test_2, \n",
    "                  num_neurons=20, \n",
    "                  epochs=5, \n",
    "                  file=f\"final_basic_2_{j}.txt\"\n",
    "        )\n",
    "    )\n",
    "end = time()\n",
    "avg_res = round(sum(res_basic_2) / len(res_basic_2), 2)\n",
    "avg_time = round(end - start)\n",
    "df_2.loc[-1] = ['basic', avg_res, avg_time]\n",
    "df_2.index = df_2.index + 1\n",
    "df_2 = df_2.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecb547ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch num: 1\n",
      "epoch num: 2\n",
      "epoch num: 3\n",
      "epoch num: 4\n",
      "epoch num: 5\n",
      "Test\tL2: 5.51\n",
      "epoch num: 1\n",
      "epoch num: 2\n",
      "epoch num: 3\n",
      "epoch num: 4\n",
      "epoch num: 5\n",
      "Test\tL2: 5.44\n",
      "epoch num: 1\n",
      "epoch num: 2\n",
      "epoch num: 3\n",
      "epoch num: 4\n",
      "epoch num: 5\n",
      "Test\tL2: 5.45\n"
     ]
    }
   ],
   "source": [
    "res_basic_3 = []\n",
    "start = time()\n",
    "for j in range(3):\n",
    "    res_basic_3.append(\n",
    "        basic(scaled_X_train_3, y_train_3, scaled_X_test_3, y_test_3, \n",
    "                  num_neurons=20, \n",
    "                  epochs=5, \n",
    "                  file=f\"final_basic_3_{j}.txt\"\n",
    "        )\n",
    "    )\n",
    "end = time()\n",
    "avg_res = round(sum(res_basic_3) / len(res_basic_3), 2)\n",
    "avg_time = round(end - start)\n",
    "df_3.loc[-1] = ['basic', avg_res, avg_time]\n",
    "df_3.index = df_3.index + 1\n",
    "df_3 = df_3.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c9446",
   "metadata": {},
   "source": [
    "## Jog of Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8af92e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, scheduler, loss, inputs, targets, count_nn, epochs):\n",
    "    \n",
    "    model.train()\n",
    "    step = inputs.shape[0] // count_nn\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f'\\nepoch num: {epoch}')\n",
    "        for i, row in enumerate(inputs):\n",
    "\n",
    "            data = torch.tensor(row).type(torch.FloatTensor).to(device)\n",
    "            target = torch.tensor(np.array(targets.iloc[i])).type(torch.FloatTensor).to(device).view(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(data)\n",
    "            loss_value = loss(pred, target)\n",
    "\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            # scheduler.step(loss_value)\n",
    "\n",
    "            if i % step == step - 1:\n",
    "                print(i, end=' ')\n",
    "                check_points(model, i, step, inputs, targets)\n",
    "                model.train()\n",
    "\n",
    "\n",
    "def check_points(model, i, step, inputs, targets):\n",
    "    losses = []\n",
    "    weights = {'fc1.weight': [], 'fc1.bias': [], 'fc2.weight': [], 'fc2.bias': []}\n",
    "    for name, param in model.named_parameters():\n",
    "        weights[name].append(param.data)\n",
    "    for _ in range(9):\n",
    "        for name, param in model.named_parameters():\n",
    "            param.data += (randint(-1, 1) / 20)\n",
    "        losses.append(test_model(model, inputs[i-step+1:i], targets[i-step+1:i]))\n",
    "        for name, param in model.named_parameters():\n",
    "            weights[name].append(param.data)\n",
    "    for name, param in model.named_parameters():\n",
    "        param.data = weights[name][losses.index(min(losses))]\n",
    "\n",
    "\n",
    "def test_model(model, inputs, targets, file=\"test.txt\", is_show=False):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    running_l2 = 0.  \n",
    "    if is_show:\n",
    "        with open(file, 'w') as f:\n",
    "            pass\n",
    "\n",
    "    for i, row in enumerate(inputs):\n",
    "        data = torch.tensor(row).type(torch.FloatTensor).to(device)\n",
    "        target = torch.tensor(np.array(targets.iloc[i])).type(torch.FloatTensor).to(device).view(1)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred = model(data)\n",
    "        if is_show:\n",
    "            r = '{} Pred: {:.4f} Target: {:.4f}'.format(i, round(pred.item()), target.item())\n",
    "            with open(file, 'a') as f:\n",
    "                f.write(r + '\\n')\n",
    "\n",
    "        eps = abs(target.item() - pred.item())\n",
    "        running_l2 += eps ** 2\n",
    "\n",
    "    l2 = (running_l2 / inputs.shape[0]) ** 0.5\n",
    "    if is_show:\n",
    "        with open(file, 'a') as f:\n",
    "            f.write(f'L2: {round(l2, 2)}')\n",
    "        print('\\nTest\\tL2: {:.2f}'.format(l2))\n",
    "\n",
    "    return l2\n",
    "\n",
    "\n",
    "def jog(scaled_X_train, y_train, scaled_X_test, y_test, num_neurons, count_nn, epochs, file):\n",
    "    loss = nn.MSELoss()\n",
    "    model = NeuronNetwork(num_input=scaled_X_train.shape[1], num_neurons=num_neurons).to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10000, min_lr=1e-06)\n",
    "\n",
    "    train_model(model, optimizer, scheduler, loss, scaled_X_train, y_train, count_nn, epochs=epochs)\n",
    "    return test_model(model, scaled_X_test, y_test, file, is_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ae7a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch num: 1\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "epoch num: 2\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "epoch num: 3\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "epoch num: 4\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "epoch num: 5\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "Test\tL2: 8.79\n",
      "\n",
      "epoch num: 1\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "epoch num: 2\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "epoch num: 3\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "epoch num: 4\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "epoch num: 5\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "Test\tL2: 3.25\n",
      "\n",
      "epoch num: 1\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "epoch num: 2\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "epoch num: 3\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "epoch num: 4\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "epoch num: 5\n",
      "509 1019 1529 2039 2549 3059 3569 4079 4589 5099 \n",
      "Test\tL2: 4.38\n"
     ]
    }
   ],
   "source": [
    "res_jog_1 = []\n",
    "start = time()\n",
    "for j in range(3):\n",
    "    res_jog_1.append(\n",
    "        jog(scaled_X_train_1, y_train_1, scaled_X_test_1, y_test_1, \n",
    "                  num_neurons=20, \n",
    "                  count_nn=10, \n",
    "                  epochs=5, \n",
    "                  file=f\"final_jog_1_{j}.txt\"\n",
    "        )\n",
    "    )\n",
    "end = time()\n",
    "avg_res = round(sum(res_jog_1) / len(res_jog_1), 2)\n",
    "avg_time = round(end - start)\n",
    "df_1.loc[-1] = ['jog', avg_res, avg_time]\n",
    "df_1.index = df_1.index + 1\n",
    "df_1 = df_1.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e3f2d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch num: 1\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "epoch num: 2\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "epoch num: 3\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "epoch num: 4\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "epoch num: 5\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "Test\tL2: 5.76\n",
      "\n",
      "epoch num: 1\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "epoch num: 2\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "epoch num: 3\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "epoch num: 4\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "epoch num: 5\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "Test\tL2: 4.89\n",
      "\n",
      "epoch num: 1\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "epoch num: 2\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "epoch num: 3\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "epoch num: 4\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "epoch num: 5\n",
      "15 31 47 63 79 95 111 127 143 159 \n",
      "Test\tL2: 6.14\n"
     ]
    }
   ],
   "source": [
    "res_jog_2 = []\n",
    "start = time()\n",
    "for j in range(3):\n",
    "    res_jog_2.append(\n",
    "        jog(scaled_X_train_2, y_train_2, scaled_X_test_2, y_test_2, \n",
    "                  num_neurons=20, \n",
    "                  count_nn=10, \n",
    "                  epochs=5, \n",
    "                  file=f\"final_jog_2_{j}.txt\"\n",
    "        )\n",
    "    )\n",
    "end = time()\n",
    "avg_res = round(sum(res_jog_2) / len(res_jog_2), 2)\n",
    "avg_time = round(end - start)\n",
    "df_2.loc[-1] = ['jog', avg_res, avg_time]\n",
    "df_2.index = df_2.index + 1\n",
    "df_2 = df_2.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b99e5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch num: 1\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "epoch num: 2\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "epoch num: 3\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "epoch num: 4\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "epoch num: 5\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "Test\tL2: 7.36\n",
      "\n",
      "epoch num: 1\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "epoch num: 2\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "epoch num: 3\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "epoch num: 4\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "epoch num: 5\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "Test\tL2: 6.14\n",
      "\n",
      "epoch num: 1\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "epoch num: 2\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "epoch num: 3\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "epoch num: 4\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "epoch num: 5\n",
      "39 79 119 159 199 239 279 319 359 399 \n",
      "Test\tL2: 6.32\n"
     ]
    }
   ],
   "source": [
    "res_jog_3 = []\n",
    "start = time()\n",
    "for j in range(3):\n",
    "    res_jog_3.append(\n",
    "        jog(scaled_X_train_3, y_train_3, scaled_X_test_3, y_test_3, \n",
    "                  num_neurons=20, \n",
    "                  count_nn=10, \n",
    "                  epochs=5, \n",
    "                  file=f\"final_jog_3_{j}.txt\"\n",
    "        )\n",
    "    )\n",
    "end = time()\n",
    "avg_res = round(sum(res_jog_3) / len(res_jog_3), 2)\n",
    "avg_time = round(end - start)\n",
    "df_3.loc[-1] = ['jog', avg_res, avg_time]\n",
    "df_3.index = df_3.index + 1\n",
    "df_3 = df_3.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416bfa7a",
   "metadata": {},
   "source": [
    "## Genetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c33ba0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, loss, inputs, targets, epochs):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        for i, row in enumerate(inputs):\n",
    "\n",
    "            data = torch.tensor(row).type(torch.FloatTensor).to(device)\n",
    "            target = torch.tensor(np.array(targets.iloc[i])).type(torch.FloatTensor).to(device).view(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(data)\n",
    "            loss_value = loss(pred, target)\n",
    "\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_model(model, inputs, targets, file=\"test.txt\", is_show=False):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    running_l2 = 0.  \n",
    "    if is_show:\n",
    "        with open(file, 'w') as f:\n",
    "            pass\n",
    "\n",
    "    for i, row in enumerate(inputs):\n",
    "        data = torch.tensor(row).type(torch.FloatTensor).to(device)\n",
    "        target = torch.tensor(np.array(targets.iloc[i])).type(torch.FloatTensor).to(device).view(1)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred = model(data)\n",
    "        if is_show:\n",
    "            r = '{} Pred: {:.4f} Target: {:.4f}'.format(i, round(pred.item()), target.item())\n",
    "            with open(file, 'a') as f:\n",
    "                f.write(r + '\\n')\n",
    "\n",
    "        eps = abs(target.item() - pred.item())\n",
    "        running_l2 += eps ** 2\n",
    "\n",
    "    l2 = (running_l2 / inputs.shape[0]) ** 0.5\n",
    "    if is_show:\n",
    "        with open(file, 'a') as f:\n",
    "            f.write(f'L2: {round(l2, 2)}')\n",
    "        print('Test\\tL2: {:.2f}'.format(l2), flush=True)\n",
    "\n",
    "    return l2\n",
    "\n",
    "\n",
    "def check_parents(models, step, start_ind, scaled_X_train, y_train):\n",
    "    res = []\n",
    "    for i in range(len(models)):\n",
    "        res.append((i, \n",
    "                    test_model(models[i], \n",
    "                               scaled_X_train[start_ind:start_ind+step], \n",
    "                               y_train.iloc[start_ind:start_ind+step])))\n",
    "    results = sorted(res, key=lambda x: x[1])\n",
    "    return results[:6]\n",
    "\n",
    "\n",
    "def train_parents(models, best_result_parents, step, start_ind, scaled_X_train, y_train, epochs):\n",
    "    trained_best_parents = []\n",
    "    print(start_ind, epochs)\n",
    "    for i in range(len(best_result_parents)):\n",
    "        trained_best_parents.append(train_model(models[best_result_parents[i][0]], \n",
    "                                                optim.SGD(models[best_result_parents[i][0]].parameters(), lr=0.001),\n",
    "                                                nn.MSELoss(),\n",
    "                                                scaled_X_train[start_ind:start_ind+step], \n",
    "                                                y_train[start_ind:start_ind+step],\n",
    "                                                epochs=epochs))\n",
    "    return trained_best_parents\n",
    "\n",
    "\n",
    "def save_weights_parents(trained_best_parents):\n",
    "    weights_parents = []\n",
    "    for num in range(len(trained_best_parents)):\n",
    "        weights_model = []\n",
    "        for name, param in trained_best_parents[num].named_parameters():\n",
    "            weights_model.append(param.data)\n",
    "        weights_parents.append(weights_model)\n",
    "    return weights_parents\n",
    "\n",
    "\n",
    "def crossingover(trained_best_parents, weights_parents, num_neurons, num_input, p_cross, p_mut):\n",
    "\n",
    "    new_models = []\n",
    "\n",
    "    for ind_parent_1 in range(len(trained_best_parents)-1):\n",
    "        for ind_parent_2 in range(ind_parent_1+1, len(trained_best_parents)):\n",
    "            if random() < p_cross:\n",
    "                children_1 = NeuronNetwork(num_input=num_input, num_neurons=num_neurons).to(device)\n",
    "                children_2 = NeuronNetwork(num_input=num_input, num_neurons=num_neurons).to(device)\n",
    "\n",
    "                ch_1_params = [torch.zeros([num_neurons, num_input]).to(device), torch.zeros([num_neurons]).to(device), \n",
    "                               torch.zeros([1, num_neurons]).to(device), torch.zeros([1]).to(device)]\n",
    "                ch_2_params = [torch.zeros([num_neurons, num_input]).to(device), torch.zeros([num_neurons]).to(device), \n",
    "                               torch.zeros([1, num_neurons]).to(device), torch.zeros([1]).to(device)]\n",
    "\n",
    "                for num_neuron in range(num_neurons):\n",
    "                    for num_inputs in range(num_input):\n",
    "                        if random() < 0.5:\n",
    "                            ch_1_params[0][num_neuron][num_inputs] = weights_parents[ind_parent_1][0][num_neuron][num_inputs]\n",
    "                            if random() < p_mut:\n",
    "                                ch_1_params[0][num_neuron][num_inputs] += (randint(-1, 1) / 20) \n",
    "\n",
    "                            ch_2_params[0][num_neuron][num_inputs] = weights_parents[ind_parent_2][0][num_neuron][num_inputs]\n",
    "                            if random() < p_mut:\n",
    "                                ch_2_params[0][num_neuron][num_inputs] += (randint(-1, 1) / 20)\n",
    "\n",
    "                        else:\n",
    "                            ch_1_params[0][num_neuron][num_inputs] = weights_parents[ind_parent_2][0][num_neuron][num_inputs]\n",
    "                            if random() < p_mut:\n",
    "                                ch_1_params[0][num_neuron][num_inputs] += (randint(-1, 1) / 20) \n",
    "\n",
    "                            ch_2_params[0][num_neuron][num_inputs] = weights_parents[ind_parent_1][0][num_neuron][num_inputs]\n",
    "                            if random() < p_mut:\n",
    "                                ch_2_params[0][num_neuron][num_inputs] += (randint(-1, 1) / 20)       \n",
    "                \n",
    "                for num_neuron in range(num_neurons):\n",
    "                    if random() < 0.5:\n",
    "                        ch_1_params[1][num_neuron] = weights_parents[ind_parent_1][1][num_neuron]\n",
    "                        if random() < p_mut:\n",
    "                            ch_1_params[1][num_neuron] += (randint(-1, 1) / 20) \n",
    "\n",
    "                        ch_2_params[1][num_neuron] = weights_parents[ind_parent_2][1][num_neuron]\n",
    "                        if random() < p_mut:\n",
    "                            ch_2_params[1][num_neuron] += (randint(-1, 1) / 20) \n",
    "                    \n",
    "                    else:\n",
    "                        ch_1_params[1][num_neuron] = weights_parents[ind_parent_2][1][num_neuron]\n",
    "                        if random() < p_mut:\n",
    "                            ch_1_params[1][num_neuron] += (randint(-1, 1) / 20) \n",
    "\n",
    "                        ch_2_params[1][num_neuron] = weights_parents[ind_parent_1][1][num_neuron]\n",
    "                        if random() < p_mut:\n",
    "                            ch_2_params[1][num_neuron] += (randint(-1, 1) / 20)   \n",
    "\n",
    "                for num_neuron in range(num_neurons):\n",
    "                    if random() < 0.5:\n",
    "                        ch_1_params[2][0][num_neuron] = weights_parents[ind_parent_1][2][0][num_neuron]\n",
    "                        if random() < p_mut:\n",
    "                            ch_1_params[2][0][num_neuron] += (randint(-1, 1) / 20) \n",
    "\n",
    "                        ch_2_params[2][0][num_neuron] = weights_parents[ind_parent_2][2][0][num_neuron]\n",
    "                        if random() < p_mut:\n",
    "                            ch_2_params[2][0][num_neuron] += (randint(-1, 1) / 20) \n",
    "\n",
    "                    else:\n",
    "                        ch_1_params[2][0][num_neuron] = weights_parents[ind_parent_2][2][0][num_neuron]\n",
    "                        if random() < p_mut:\n",
    "                            ch_1_params[2][0][num_neuron] += (randint(-1, 1) / 20) \n",
    "\n",
    "                        ch_2_params[2][0][num_neuron] = weights_parents[ind_parent_1][2][0][num_neuron]\n",
    "                        if random() < p_mut:\n",
    "                            ch_2_params[2][0][num_neuron] += (randint(-1, 1) / 20)  \n",
    "\n",
    "                if random() < 0.5:\n",
    "                    ch_1_params[3][0] = weights_parents[ind_parent_1][3][0]\n",
    "                    if random() < p_mut:\n",
    "                        ch_1_params[3][0] += (randint(-1, 1) / 20) \n",
    "\n",
    "                    ch_2_params[3][0] = weights_parents[ind_parent_2][3][0]\n",
    "                    if random() < p_mut:\n",
    "                        ch_2_params[3][0] += (randint(-1, 1) / 20) \n",
    "\n",
    "                else:\n",
    "                    ch_1_params[3][0] = weights_parents[ind_parent_2][3][0]\n",
    "                    if random() < p_mut:\n",
    "                        ch_1_params[3][0] += (randint(-1, 1) / 20) \n",
    "\n",
    "                    ch_2_params[3][0] = weights_parents[ind_parent_1][3][0]\n",
    "                    if random() < p_mut:\n",
    "                        ch_2_params[3][0] += (randint(-1, 1) / 20)  \n",
    "                            \n",
    "                for num, el in enumerate(children_1.named_parameters()):\n",
    "                    el[1].data = ch_1_params[num]\n",
    "                new_models.append(children_1)  \n",
    "\n",
    "                for num, el in enumerate(children_2.named_parameters()):\n",
    "                    el[1].data = ch_2_params[num]   \n",
    "                new_models.append(children_2)\n",
    "\n",
    "    return new_models\n",
    "\n",
    "\n",
    "def reduction(new_models):\n",
    "    shuffle(new_models)\n",
    "    return new_models[:20]\n",
    "\n",
    "\n",
    "def func(models, step, start_ind, scaled_X_train, scaled_X_test, y_train, y_test, num_neurons, epochs, p_cross, p_mut):\n",
    "    best_result_parents = check_parents(models, step, start_ind, scaled_X_train, y_train)\n",
    "    trained_best_parents = train_parents(models, best_result_parents, step, start_ind, scaled_X_train, y_train, epochs)\n",
    "    weights_parents = save_weights_parents(trained_best_parents)\n",
    "    new_models = crossingover(trained_best_parents, weights_parents, num_neurons, scaled_X_train.shape[1], p_cross, p_mut)\n",
    "    results = reduction(new_models)\n",
    "    return results\n",
    "\n",
    "\n",
    "def genetic(scaled_X_train, y_train, scaled_X_test, y_test, num_neurons, count_nn, epochs, file):\n",
    "    models = [NeuronNetwork(num_input=scaled_X_test.shape[1], num_neurons=num_neurons).to(device) for _ in range(20)]\n",
    "    limited_len_scaled_x_train = len(scaled_X_train) // count_nn * count_nn\n",
    "    step = limited_len_scaled_x_train // count_nn\n",
    "    \n",
    "    for start_ind in range(0, limited_len_scaled_x_train, step):\n",
    "        models = func(models, step, start_ind, scaled_X_train, scaled_X_test, y_train, y_test, num_neurons, epochs, p_cross=0.9, p_mut=0.1)\n",
    "\n",
    "    res_tests = []\n",
    "    for model in models:\n",
    "        res_tests.append(test_model(model, scaled_X_test, y_test))\n",
    "        \n",
    "    return test_model(models[res_tests.index(min(res_tests))], scaled_X_test, y_test, file=file, is_show=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1842608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n",
      "510 5\n",
      "1020 5\n",
      "1530 5\n",
      "2040 5\n",
      "2550 5\n",
      "3060 5\n",
      "3570 5\n",
      "4080 5\n",
      "4590 5\n",
      "Test\tL2: 2.14\n",
      "0 5\n",
      "510 5\n",
      "1020 5\n",
      "1530 5\n",
      "2040 5\n",
      "2550 5\n",
      "3060 5\n",
      "3570 5\n",
      "4080 5\n",
      "4590 5\n",
      "Test\tL2: 2.13\n",
      "0 5\n",
      "510 5\n",
      "1020 5\n",
      "1530 5\n",
      "2040 5\n",
      "2550 5\n",
      "3060 5\n",
      "3570 5\n",
      "4080 5\n",
      "4590 5\n",
      "Test\tL2: 2.13\n"
     ]
    }
   ],
   "source": [
    "res_genetic_1 = []\n",
    "start = time()\n",
    "for j in range(3):\n",
    "    res_genetic_1.append(\n",
    "        genetic(scaled_X_train_1, y_train_1, scaled_X_test_1, y_test_1, \n",
    "                  num_neurons=20, \n",
    "                  count_nn=10, \n",
    "                  epochs=5, \n",
    "                  file=f\"final_genetic_1_{j}.txt\"\n",
    "        )\n",
    "    )\n",
    "end = time()\n",
    "avg_res = round(sum(res_genetic_1) / len(res_genetic_1), 2)\n",
    "avg_time = round(end - start)\n",
    "df_1.loc[-1] = ['genetic', avg_res, avg_time]\n",
    "df_1.index = df_1.index + 1\n",
    "df_1 = df_1.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "613303f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n",
      "16 5\n",
      "32 5\n",
      "48 5\n",
      "64 5\n",
      "80 5\n",
      "96 5\n",
      "112 5\n",
      "128 5\n",
      "144 5\n",
      "Test\tL2: 4.54\n",
      "0 5\n",
      "16 5\n",
      "32 5\n",
      "48 5\n",
      "64 5\n",
      "80 5\n",
      "96 5\n",
      "112 5\n",
      "128 5\n",
      "144 5\n",
      "Test\tL2: 4.79\n",
      "0 5\n",
      "16 5\n",
      "32 5\n",
      "48 5\n",
      "64 5\n",
      "80 5\n",
      "96 5\n",
      "112 5\n",
      "128 5\n",
      "144 5\n",
      "Test\tL2: 4.47\n"
     ]
    }
   ],
   "source": [
    "res_genetic_2 = []\n",
    "start = time()\n",
    "for j in range(3):\n",
    "    res_genetic_2.append(\n",
    "        genetic(scaled_X_train_2, y_train_2, scaled_X_test_2, y_test_2, \n",
    "                  num_neurons=20, \n",
    "                  count_nn=10, \n",
    "                  epochs=5, \n",
    "                  file=f\"final_genetic_2_{j}.txt\"\n",
    "        )\n",
    "    )\n",
    "end = time()\n",
    "avg_res = round(sum(res_genetic_2) / len(res_genetic_2), 2)\n",
    "avg_time = round(end - start)\n",
    "df_2.loc[-1] = ['genetic', avg_res, avg_time]\n",
    "df_2.index = df_2.index + 1\n",
    "df_2 = df_2.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9850a56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n",
      "40 5\n",
      "80 5\n",
      "120 5\n",
      "160 5\n",
      "200 5\n",
      "240 5\n",
      "280 5\n",
      "320 5\n",
      "360 5\n",
      "Test\tL2: 5.28\n",
      "0 5\n",
      "40 5\n",
      "80 5\n",
      "120 5\n",
      "160 5\n",
      "200 5\n",
      "240 5\n",
      "280 5\n",
      "320 5\n",
      "360 5\n",
      "Test\tL2: 5.36\n",
      "0 5\n",
      "40 5\n",
      "80 5\n",
      "120 5\n",
      "160 5\n",
      "200 5\n",
      "240 5\n",
      "280 5\n",
      "320 5\n",
      "360 5\n",
      "Test\tL2: 5.31\n"
     ]
    }
   ],
   "source": [
    "res_genetic_3 = []\n",
    "start = time()\n",
    "for j in range(3):\n",
    "    res_genetic_3.append(\n",
    "        genetic(scaled_X_train_3, y_train_3, scaled_X_test_3, y_test_3, \n",
    "                  num_neurons=20, \n",
    "                  count_nn=10, \n",
    "                  epochs=5, \n",
    "                  file=f\"final_genetic_3_{j}.txt\"\n",
    "        )\n",
    "    )\n",
    "end = time()\n",
    "avg_res = round(sum(res_genetic_3) / len(res_genetic_3), 2)\n",
    "avg_time = round(end - start)\n",
    "df_3.loc[-1] = ['genetic', avg_res, avg_time]\n",
    "df_3.index = df_3.index + 1\n",
    "df_3 = df_3.sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea965c",
   "metadata": {},
   "source": [
    "## Argon Jog of Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c42e0ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(models_elements, data, target):\n",
    "\n",
    "    model, optimizer, scheduler, loss = models_elements\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad() \n",
    "\n",
    "    pred = model(data)\n",
    "    loss_value = loss(pred, target)\n",
    "\n",
    "    loss_value.backward()\n",
    "    optimizer.step()\n",
    "    # scheduler.step(loss_value)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "def test_model(model, inputs, targets, file=\"test.txt\"):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    running_l2 = 0.  \n",
    "    with open(file, 'w') as f:\n",
    "        pass\n",
    "\n",
    "    for i, row in enumerate(inputs):\n",
    "        data = torch.tensor(row).type(torch.FloatTensor).to(device)\n",
    "        target = torch.tensor(np.array(targets.iloc[i])).type(torch.FloatTensor).to(device).view(1)\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            pred = model(data)\n",
    "        r = '{} Pred: {:.4f} Target: {:.4f}'.format(i, round(pred.item()), target.item())\n",
    "        with open(file, 'a') as f:\n",
    "            f.write(r + '\\n')\n",
    "\n",
    "        eps = abs(target.item() - pred.item())\n",
    "        running_l2 += eps ** 2\n",
    "\n",
    "    l2 = (running_l2 / inputs.shape[0]) ** 0.5\n",
    "    with open(file, 'a') as f:\n",
    "        f.write(f'L2: {round(l2, 2)}')\n",
    "    print('Test\\tL2: {:.2f}'.format(l2), flush=True)\n",
    "\n",
    "    return l2\n",
    "    \n",
    "    \n",
    "def argon_jog(scaled_X_train, y_train, scaled_X_test, y_test, num_neurons, count_nn, epochs, file):\n",
    "\n",
    "    num_input = scaled_X_train.shape[1]\n",
    "    limited_len_scaled_x_train = len(scaled_X_train) // count_nn * count_nn\n",
    "    models_elements = []\n",
    "    final_weights = []\n",
    "    cur_epoch = 0\n",
    "\n",
    "    for i in tqdm(range(limited_len_scaled_x_train * (epochs + 1) - limited_len_scaled_x_train // count_nn)):\n",
    "        if i % limited_len_scaled_x_train == 0 and cur_epoch < epochs:\n",
    "            cur_epoch += 1\n",
    "        if i % (len(scaled_X_train) // count_nn) == 0 and i < limited_len_scaled_x_train:\n",
    "            model_new = NeuronNetwork(num_input=num_input, num_neurons=num_neurons, number=i).to(device)\n",
    "            for name, params in model_new.named_parameters():\n",
    "                params.data *= randint(1, 5)\n",
    "            optimizer_new = optim.SGD(model_new.parameters(), lr=0.001)\n",
    "            scheduler_new = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_new, patience=1000, min_lr=1e-06)\n",
    "            loss = nn.MSELoss()\n",
    "            models_elements.append((model_new, optimizer_new, scheduler_new, loss))\n",
    "\n",
    "        weigths_models, is_del = [], False\n",
    "        for model_num in range(len(models_elements)):\n",
    "\n",
    "            if models_elements[model_num][0].number == 0 or random() < 1 / (count_nn ** 0.5):\n",
    "                current_row = i - models_elements[model_num][0].number - (cur_epoch - 1) * limited_len_scaled_x_train\n",
    "\n",
    "                if current_row >= limited_len_scaled_x_train:\n",
    "                    is_del = True\n",
    "                    continue\n",
    "\n",
    "                data = torch.tensor(scaled_X_train[current_row]).type(torch.FloatTensor).to(device)\n",
    "                target = torch.tensor(np.array(y_train.iloc[current_row])).type(torch.FloatTensor).to(device).view(1)\n",
    "                train_model(models_elements[model_num], data, target)\n",
    "                \n",
    "                line_fc1_weight = models_elements[model_num][0].fc1.weight.data.reshape(num_input*num_neurons,)\n",
    "                line_fc1_bias = models_elements[model_num][0].fc1.bias.data\n",
    "                line_fc2_weight = models_elements[model_num][0].fc2.weight.data.reshape(num_neurons,)\n",
    "                line_fc2_bias = models_elements[model_num][0].fc2.bias.data\n",
    "                line_torch = torch.cat((line_fc1_weight, line_fc1_bias, line_fc2_weight, line_fc2_bias), 0) \n",
    "                \n",
    "                sum_line_torch = sum([weigths_models[0] * (j + 1) for j in range(len(weigths_models))]) + line_torch * (len(weigths_models) + 1)\n",
    "                count_line_torch = sum(range(1, len(weigths_models) + 1)) + len(weigths_models) + 1\n",
    "                new_line_torch = sum_line_torch / count_line_torch\n",
    "                #new_line_torch = (sum(weigths_models) + line_torch) / (len(weigths_models) + 1)\n",
    "                weigths_models.append(new_line_torch)\n",
    "\n",
    "                for name, params in models_elements[model_num][0].named_parameters():\n",
    "                    if name == 'fc1.weight':\n",
    "                        params.data = new_line_torch[:num_neurons*num_input].reshape(num_neurons, num_input)\n",
    "                    elif name == 'fc1.bias':\n",
    "                        params.data = new_line_torch[num_neurons*num_input:num_neurons*(num_input+1)]\n",
    "                    elif name == 'fc2.weight':\n",
    "                        params.data = new_line_torch[num_neurons*(num_input+1):num_neurons*(num_input+2)].reshape(1, num_neurons)\n",
    "                    elif name == 'fc2.bias':\n",
    "                        params.data = new_line_torch[num_neurons*(num_input+2):num_neurons*(num_input+2)+1]\n",
    "        \n",
    "        if is_del:\n",
    "            finish_model = models_elements.pop(0)[0]\n",
    "            line_fc1_weight = finish_model.fc1.weight.data.reshape(num_input*num_neurons,)\n",
    "            line_fc1_bias = finish_model.fc1.bias.data\n",
    "            line_fc2_weight = finish_model.fc2.weight.data.reshape(num_neurons,)\n",
    "            line_fc2_bias = finish_model.fc2.bias.data\n",
    "            line_torch = torch.cat((line_fc1_weight, line_fc1_bias, line_fc2_weight, line_fc2_bias), 0) \n",
    "            final_weights.append(line_torch)\n",
    "\n",
    "    avg_final_weights = sum(final_weights) / len(final_weights)\n",
    "\n",
    "    model_final = NeuronNetwork(num_input=num_input, num_neurons=num_neurons, number=5100).to(device)\n",
    "\n",
    "    for name, params in model_final.named_parameters():\n",
    "        if name == 'fc1.weight':\n",
    "            params.data = avg_final_weights[:num_neurons*num_input].reshape(num_neurons, num_input)\n",
    "        elif name == 'fc1.bias':\n",
    "            params.data = avg_final_weights[num_neurons*num_input:num_neurons*(num_input+1)]\n",
    "        elif name == 'fc2.weight':\n",
    "            params.data = avg_final_weights[num_neurons*(num_input+1):num_neurons*(num_input+2)].reshape(1, num_neurons)\n",
    "        elif name == 'fc2.bias':\n",
    "            params.data = avg_final_weights[num_neurons*(num_input+2):num_neurons*(num_input+2)+1]\n",
    "\n",
    "    return test_model(model_final, scaled_X_test, y_test, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b123bada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30090/30090 [03:14<00:00, 154.74it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\tL2: 2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30090/30090 [03:57<00:00, 126.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\tL2: 2.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30090/30090 [03:49<00:00, 130.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\tL2: 2.15\n"
     ]
    }
   ],
   "source": [
    "res_argon_jog_1 = []\n",
    "start = time()\n",
    "for j in range(3):\n",
    "    res_argon_jog_1.append(\n",
    "        argon_jog(scaled_X_train_1, y_train_1, scaled_X_test_1, y_test_1, \n",
    "                  num_neurons=20, \n",
    "                  count_nn=10, \n",
    "                  epochs=5, \n",
    "                  file=f\"final_argon_jog_1_{j}.txt\"\n",
    "        )\n",
    "    )\n",
    "end = time()\n",
    "avg_res = round(sum(res_argon_jog_1) / len(res_argon_jog_1), 2)\n",
    "avg_time = round(end - start)\n",
    "df_1.loc[-1] = ['argon jog', avg_res, avg_time]\n",
    "df_1.index = df_1.index + 1\n",
    "df_1 = df_1.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b63f5a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 944/944 [00:08<00:00, 111.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\tL2: 4.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 944/944 [00:07<00:00, 124.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\tL2: 4.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 944/944 [00:07<00:00, 119.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\tL2: 4.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_argon_jog_2 = []\n",
    "start = time()\n",
    "for j in range(3):\n",
    "    res_argon_jog_2.append(\n",
    "        argon_jog(scaled_X_train_2, y_train_2, scaled_X_test_2, y_test_2, \n",
    "                  num_neurons=20, \n",
    "                  count_nn=10, \n",
    "                  epochs=5, \n",
    "                  file=f\"final_argon_jog_2_{j}.txt\"\n",
    "        )\n",
    "    )\n",
    "end = time()\n",
    "avg_res = round(sum(res_argon_jog_2) / len(res_argon_jog_2), 2)\n",
    "avg_time = round(end - start)\n",
    "df_2.loc[-1] = ['argon jog', avg_res, avg_time]\n",
    "df_2.index = df_2.index + 1\n",
    "df_2 = df_2.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7745f6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2360/2360 [00:19<00:00, 119.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\tL2: 5.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2360/2360 [00:17<00:00, 133.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\tL2: 5.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2360/2360 [00:12<00:00, 189.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\tL2: 5.78\n"
     ]
    }
   ],
   "source": [
    "res_argon_jog_3 = []\n",
    "start = time()\n",
    "for j in range(3):\n",
    "    res_argon_jog_3.append(\n",
    "        argon_jog(scaled_X_train_3, y_train_3, scaled_X_test_3, y_test_3, \n",
    "                  num_neurons=20, \n",
    "                  count_nn=10, \n",
    "                  epochs=5, \n",
    "                  file=f\"final_argon_jog_3_{j}.txt\"\n",
    "        )\n",
    "    )\n",
    "end = time()\n",
    "avg_res = round(sum(res_argon_jog_3) / len(res_argon_jog_3), 2)\n",
    "avg_time = round(end - start)\n",
    "df_3.loc[-1] = ['argon jog', avg_res, avg_time]\n",
    "df_3.index = df_3.index + 1\n",
    "df_3 = df_3.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda038b0",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "152b9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.iloc[::-1].reset_index(drop=True)\n",
    "df_2 = df_2.iloc[::-1].reset_index(drop=True)\n",
    "df_3 = df_3.iloc[::-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3202810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>L2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic</td>\n",
       "      <td>2.12</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jog</td>\n",
       "      <td>5.47</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genetic</td>\n",
       "      <td>2.13</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>argon jog</td>\n",
       "      <td>2.13</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method    L2  time\n",
       "0      basic  2.12   125\n",
       "1        jog  5.47   391\n",
       "2    genetic  2.13   871\n",
       "3  argon jog  2.13   666"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.to_csv('final_1_result.csv')\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b42dfd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>L2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic</td>\n",
       "      <td>4.84</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jog</td>\n",
       "      <td>5.59</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genetic</td>\n",
       "      <td>4.60</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>argon jog</td>\n",
       "      <td>4.57</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method    L2  time\n",
       "0      basic  4.84     6\n",
       "1        jog  5.59    16\n",
       "2    genetic  4.60    40\n",
       "3  argon jog  4.57    24"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.to_csv('final_2_result.csv')\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2c652c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>L2</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>basic</td>\n",
       "      <td>5.47</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jog</td>\n",
       "      <td>6.61</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>genetic</td>\n",
       "      <td>5.32</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>argon jog</td>\n",
       "      <td>5.55</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method    L2  time\n",
       "0      basic  5.47    12\n",
       "1        jog  6.61    37\n",
       "2    genetic  5.32    71\n",
       "3  argon jog  5.55    50"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.to_csv('final_3_result.csv')\n",
    "df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077843dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87304785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af3dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e8b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258c38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9e240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55590 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55590/55590 [05:02<00:00, 183.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\tL2: 76.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5102/5102 [00:06<00:00, 783.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\tL2: 76.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76.34199606058407"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "models_elements = []\n",
    "new_elements = []\n",
    "count_nn = 10\n",
    "limited_len_scaled_x_train = len(scaled_X_train) // count_nn * count_nn\n",
    "final_weights = []\n",
    "epochs = 10\n",
    "cur_epoch = 0\n",
    "\n",
    "for i in tqdm(range(limited_len_scaled_x_train * (epochs + 1) - limited_len_scaled_x_train // count_nn)):\n",
    "    if i % limited_len_scaled_x_train == 0 and cur_epoch < epochs:\n",
    "        cur_epoch += 1\n",
    "    if i % (len(scaled_X_train) // count_nn) == 0 and i < limited_len_scaled_x_train:\n",
    "        model_new = NeuronNetwork(num_input=19, num_neurons=20, number=i).to(device)\n",
    "        for name, params in model_new.named_parameters():\n",
    "            params.data *= randint(1, 5)\n",
    "        optimizer_new = optim.SGD(model_new.parameters(), lr=0.001)\n",
    "        scheduler_new = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_new, patience=10000, min_lr=1e-06)\n",
    "        models_elements.append((model_new, optimizer_new, scheduler_new))\n",
    "\n",
    "    weigths_models, is_del = [], False\n",
    "    for model_num in range(len(models_elements)):\n",
    "\n",
    "        if models_elements[model_num][0].number == 0 or random() < 1 / (count_nn ** 0.5):\n",
    "            current_row = i - models_elements[model_num][0].number - (cur_epoch - 1) * limited_len_scaled_x_train\n",
    "\n",
    "            if current_row >= limited_len_scaled_x_train:\n",
    "                is_del = True\n",
    "                continue\n",
    "\n",
    "            data = torch.tensor(scaled_X_train[current_row]).type(torch.FloatTensor).to(device)\n",
    "            target = torch.tensor(np.array(y_train.iloc[current_row])).type(torch.FloatTensor).to(device).view(1)\n",
    "            train_model(models_elements[model_num], data, target, nn.MSELoss(), func_activation=F.sigmoid)\n",
    "            \n",
    "            line_fc1_weight = models_elements[model_num][0].fc1.weight.data.reshape(19*20,)\n",
    "            line_fc1_bias = models_elements[model_num][0].fc1.bias.data\n",
    "            line_fc2_weight = models_elements[model_num][0].fc2.weight.data.reshape(20,)\n",
    "            line_fc2_bias = models_elements[model_num][0].fc2.bias.data\n",
    "            line_torch = torch.cat((line_fc1_weight, line_fc1_bias, line_fc2_weight, line_fc2_bias), 0) \n",
    "            \n",
    "            sum_line_torch = sum([weigths_models[0] * (j + 1) for j in range(len(weigths_models))]) + line_torch * (len(weigths_models) + 1)\n",
    "            count_line_torch = sum(range(1, len(weigths_models) + 1)) + len(weigths_models) + 1\n",
    "            new_line_torch = sum_line_torch / count_line_torch\n",
    "            #new_line_torch = (sum(weigths_models) + line_torch) / (len(weigths_models) + 1)\n",
    "            weigths_models.append(new_line_torch)\n",
    "\n",
    "            for name, params in models_elements[model_num][0].named_parameters():\n",
    "                if name == 'fc1.weight':\n",
    "                    params.data = new_line_torch[:20*19].reshape(20, 19)\n",
    "                elif name == 'fc1.bias':\n",
    "                    params.data = new_line_torch[20*19:20*(19+1)]\n",
    "                elif name == 'fc2.weight':\n",
    "                    params.data = new_line_torch[20*(19+1):20*(19+2)].reshape(1, 20)\n",
    "                elif name == 'fc2.bias':\n",
    "                    params.data = new_line_torch[20*(19+2):20*(19+2)+1]\n",
    "    \n",
    "    if is_del:\n",
    "        finish_model = models_elements.pop(0)[0]\n",
    "        line_fc1_weight = finish_model.fc1.weight.data.reshape(19*20,)\n",
    "        line_fc1_bias = finish_model.fc1.bias.data\n",
    "        line_fc2_weight = finish_model.fc2.weight.data.reshape(20,)\n",
    "        line_fc2_bias = finish_model.fc2.bias.data\n",
    "        line_torch = torch.cat((line_fc1_weight, line_fc1_bias, line_fc2_weight, line_fc2_bias), 0) \n",
    "        final_weights.append(line_torch)\n",
    "\n",
    "avg_final_weights = sum(final_weights) / len(final_weights)\n",
    "\n",
    "model_final = NeuronNetwork(num_input=19, num_neurons=20, number=5100).to(device)\n",
    "optimizer_final = optim.SGD(model_final.parameters(), lr=0.001)\n",
    "scheduler_final = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_final, patience=10000, min_lr=1e-06)\n",
    "\n",
    "for name, params in model_final.named_parameters():\n",
    "    if name == 'fc1.weight':\n",
    "        params.data = avg_final_weights[:20*19].reshape(20, 19)\n",
    "    elif name == 'fc1.bias':\n",
    "        params.data = avg_final_weights[20*19:20*(19+1)]\n",
    "    elif name == 'fc2.weight':\n",
    "        params.data = avg_final_weights[20*(19+1):20*(19+2)].reshape(1, 20)\n",
    "    elif name == 'fc2.bias':\n",
    "        params.data = avg_final_weights[20*(19+2):20*(19+2)+1]\n",
    "\n",
    "test_model(model_final, scaled_X_test, y_test, func_activation=F.sigmoid, is_show=True, file=\"results_32_rand_weight_own_model_all_5epochs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "434a6a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5102/5102 [00:06<00:00, 782.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\tL2: 75.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.66519233371261"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in tqdm(range(len(scaled_X_train))):\n",
    "    data = torch.tensor(scaled_X_train[i]).type(torch.FloatTensor).to(device)\n",
    "    target = torch.tensor(np.array(y_train.iloc[i])).type(torch.FloatTensor).to(device).view(1)\n",
    "    train_model((model_final, optimizer_final, scheduler_final), data, target, nn.MSELoss(), func_activation=F.sigmoid)\n",
    "test_model(model_final, scaled_X_test, y_test, func_activation=F.sigmoid)#, is_show=True, file=\"results_10_rand_weight_own_model_all_5epochs_after.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b57be9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5100/5100 [06:35<00:00, 12.91it/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "models_elements = []\n",
    "count_nn\n",
    "\n",
    "for i in tqdm(range(len(scaled_X_train) // count_nn * count_nn)):\n",
    "\n",
    "    if i % (len(scaled_X_train) // count_nn) == 0:\n",
    "        model_new = NeuronNetwork(num_input=19, num_neurons=20, number=i).to(device)\n",
    "        for name, params in model_new.named_parameters():\n",
    "            params.data *= randint(1, 3)\n",
    "        optimizer_new = optim.SGD(model_new.parameters(), lr=0.001)\n",
    "        scheduler_new = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_new, patience=10000, min_lr=1e-06)\n",
    "        models_elements.append((model_new, optimizer_new, scheduler_new))\n",
    "\n",
    "    weigths_models = []\n",
    "    for model_num in range(len(models_elements)):\n",
    "        if models_elements[model_num].number == 0 or random() > 0.5:\n",
    "            current_row = i - models_elements[model_num][0].number\n",
    "            data = torch.tensor(scaled_X_train[current_row]).type(torch.FloatTensor).to(device)\n",
    "            target = torch.tensor(np.array(y_train.iloc[current_row])).type(torch.FloatTensor).to(device).view(1)\n",
    "            train_model(models_elements[model_num], data, target, nn.MSELoss(), func_activation=F.sigmoid)\n",
    "            \n",
    "            line_fc1_weight = models_elements[model_num][0].fc1.weight.data.reshape(19*20,)\n",
    "            line_fc1_bias = models_elements[model_num][0].fc1.bias.data\n",
    "            line_fc2_weight = models_elements[model_num][0].fc2.weight.data.reshape(20,)\n",
    "            line_fc2_bias = models_elements[model_num][0].fc2.bias.data\n",
    "            line_torch = torch.cat((line_fc1_weight, line_fc1_bias, line_fc2_weight, line_fc2_bias), 0) \n",
    "            \n",
    "            new_line_torch = (sum([weigths_models[0] * (j+1) for j in range(len(weigths_models))]) + line_torch * (len(weigths_models)+1)) / (sum(range(1, len(weigths_models)+1)) + len(weigths_models)+1)\n",
    "            #new_line_torch = (sum(weigths_models) + line_torch) / (len(weigths_models) + 1)\n",
    "            weigths_models.append(new_line_torch)\n",
    "\n",
    "            for name, params in models_elements[model_num][0].named_parameters():\n",
    "                if name == 'fc1.weight':\n",
    "                    params.data = new_line_torch[:20*19].reshape(20, 19)\n",
    "                elif name == 'fc1.bias':\n",
    "                    params.data = new_line_torch[20*19:20*(19+1)]\n",
    "                elif name == 'fc2.weight':\n",
    "                    params.data = new_line_torch[20*(19+1):20*(19+2)].reshape(1, 20)\n",
    "                elif name == 'fc2.bias':\n",
    "                    params.data = new_line_torch[20*(19+2):20*(19+2)+1]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
